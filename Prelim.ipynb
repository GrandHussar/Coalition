{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf3307-cc0a-48f1-b20e-2ba2d5c35eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please do note that the exam was done in a folder with visual studio an this notebook was just done for compliance\n",
    "# Code for managers py the last one with circle detection\n",
    "# Create a file called managers. py\n",
    "# This file should contain the code below:\n",
    "import cv2\n",
    "import numpy\n",
    "import time\n",
    "import filters\n",
    "\n",
    "\n",
    "n = 21\n",
    "\n",
    "\n",
    "\n",
    "class CaptureManager(object):\n",
    "    def __init__(self, capture, previewWindowManager = None, shouldMirrorPreview = False):\n",
    "        self.previewWindowManager = previewWindowManager\n",
    "        self.shouldMirrorPreview = shouldMirrorPreview\n",
    "\n",
    "        self._capture = capture\n",
    "        self._channel = 0\n",
    "        self._enteredFrame = False\n",
    "        self._frame = None\n",
    "        self._imageFilename = None\n",
    "        self._videoFilename = None\n",
    "        self._videoEncoding = None\n",
    "        self._videoWriter = None\n",
    "        self._startTime = None\n",
    "        self._framesElapsed = float(0)\n",
    "        self._fpsEstimate = None\n",
    "        n = 21\n",
    "\n",
    "    @property\n",
    "    \n",
    "    def channel (self):\n",
    "        return self._channel\n",
    "        \n",
    "    @channel.setter\n",
    "    def channel(self,value):\n",
    "        if self._channel != value:\n",
    "           self._channel = value\n",
    "           self._frame = None\n",
    "\n",
    "    @property\n",
    "    def frame(self):\n",
    "        if self._enteredFrame and self._frame is None:\n",
    "            _, self._frame = self._capture.retrieve()\n",
    "        return self._frame\n",
    "\n",
    "    @property\n",
    "    def isWritingImage(self):\n",
    "        return self._imageFilename is not None\n",
    "\n",
    "    @property\n",
    "    def isWritingVideo(self):\n",
    "        return self._videoFilename is not None\n",
    "    \n",
    "    def enterFrame(self):\n",
    "        \"\"\" Capture the next frame, if any.\"\"\"\n",
    "    \n",
    "    # First, we will check if any previous frame was exited.\n",
    "        assert not self._enteredFrame, \\\n",
    "            'previous enterFrame() had no matching exitFrame()'\n",
    "        \n",
    "        if self._capture is not None:\n",
    "           self._enteredFrame = self._capture.grab()\n",
    "\n",
    "    def exitFrame(self):\n",
    "        \"\"\"Draw to the window. Write to Files. Release the frame.\"\"\"\n",
    "    \n",
    "    #Check whether any grabbed frame is retrievable\n",
    "    #The getter may retrieve and cache the frame.\n",
    "        if self.frame is None:\n",
    "            self.enteredFrame = False\n",
    "            return\n",
    "        \n",
    "    #Update the FPS estimate and related variables.\n",
    "        if self._framesElapsed==0:\n",
    "            self._startTime = time.time()\n",
    "        else:\n",
    "            timeElapsed = time.time() - self._startTime\n",
    "            self._fpsEstimate = self._framesElapsed / timeElapsed\n",
    "        self._framesElapsed += 1\n",
    "\n",
    "        # Draw to the window , if any.\n",
    "        if self.previewWindowManager is not None:\n",
    "            if self.shouldMirrorPreview:\n",
    "                \n",
    "                mirroredFrame = numpy.fliplr(self._frame.copy()).astype(numpy.uint8)\n",
    "             \n",
    "                gray_img = cv2.cvtColor(mirroredFrame, cv2.COLOR_BGR2GRAY)\n",
    "                gray_img = cv2.GaussianBlur(gray_img,(5,5),0)\n",
    "                \n",
    "                img = cv2.medianBlur(gray_img, n) # We will change this value passed as parameter and observe results\n",
    "                \n",
    "                cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,100,\n",
    "                                            param1=50,param2=50,minRadius=0,\n",
    "                                                maxRadius=0)\n",
    "                \n",
    "                if circles is None:\n",
    "                    self.previewWindowManager.show(mirroredFrame)\n",
    "\n",
    "                \n",
    "                if circles is not None:\n",
    "                    circles = numpy.uint8(numpy.around(circles))\n",
    "                    for i in circles[0,:]:\n",
    "                        # draw the outer circle\n",
    "                        cv2.circle(mirroredFrame,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "                        # draw the center of the circle\n",
    "                        cv2.circle(mirroredFrame,(i[0],i[1]),2,(0,0,255),3)\n",
    "                    self.previewWindowManager.show(mirroredFrame)\n",
    "                \n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "            else:\n",
    "                OnlyFrame = numpy.fliplr(self._frame.copy()).astype(numpy.uint8)\n",
    "                \n",
    "             \n",
    "                gray_img = cv2.cvtColor(OnlyFrame, cv2.COLOR_BGR2GRAY)\n",
    "                gray_img = cv2.GaussianBlur(gray_img,(5,5),0)\n",
    "                \n",
    "                img = cv2.medianBlur(gray_img, n) # We will change this value passed as parameter and observe results\n",
    "                \n",
    "                cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,100,\n",
    "                                            param1=50,param2=50,minRadius=0,\n",
    "                                                maxRadius=0)\n",
    "                \n",
    "                if circles is None:\n",
    "                    self.previewWindowManager.show(OnlyFrame)\n",
    "\n",
    "                \n",
    "                if circles is not None:\n",
    "                    circles = numpy.uint8(numpy.around(circles))\n",
    "                    for i in circles[0,:]:\n",
    "                        # draw the outer circle\n",
    "                        cv2.circle(OnlyFrame,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "                        # draw the center of the circle\n",
    "                        cv2.circle(OnlyFrame,(i[0],i[1]),2,(0,0,255),3)\n",
    "                    self.previewWindowManager.show(mirroredFrame)\n",
    "                \n",
    "        #Write to the image file, if any.\n",
    "        if self.isWritingImage:\n",
    "            OnlyFrame = numpy.fliplr(self._frame.copy()).astype(numpy.uint8)\n",
    "                \n",
    "             \n",
    "            gray_img = cv2.cvtColor(OnlyFrame, cv2.COLOR_BGR2GRAY)\n",
    "            gray_img = cv2.GaussianBlur(gray_img,(5,5),0)\n",
    "                \n",
    "            img = cv2.medianBlur(gray_img, n) # We will change this value passed as parameter and observe results\n",
    "                \n",
    "            cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "            circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,100,\n",
    "                                            param1=50,param2=50,minRadius=0,\n",
    "                                                maxRadius=0)\n",
    "                \n",
    "            if circles is None:\n",
    "                    self.previewWindowManager.show(OnlyFrame)\n",
    "\n",
    "                \n",
    "            if circles is not None:\n",
    "                circles = numpy.uint8(numpy.around(circles))\n",
    "                for i in circles[0,:]:\n",
    "                        # draw the outer circle\n",
    "                    cv2.circle(OnlyFrame,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "                        # draw the center of the circle\n",
    "                    cv2.circle(OnlyFrame,(i[0],i[1]),2,(0,0,255),3)\n",
    "                    \n",
    "            cv2.imwrite(self._imageFilename, OnlyFrame)\n",
    "            self._imageFilename = None\n",
    "        \n",
    "        #Write to the video file, if any.\n",
    "        self._writeVideoFrame()\n",
    "\n",
    "        #Release the frame\n",
    "        self._frame = None\n",
    "        self._enteredFrame = False\n",
    "\n",
    "    def writeImage(self, filename):\n",
    "        \"\"\"Write the next exited frame to an image file.\"\"\"\n",
    "        self._imageFilename = filename\n",
    "\n",
    "    def startWritingVideo(self,filename,encoding = cv2.VideoWriter_fourcc('I','4','2','0')):\n",
    "        \"\"\"Start Writing exited frames to a video file\"\"\"\n",
    "        self._videoFilename = filename\n",
    "        self._videoEncoding = encoding\n",
    "    \n",
    "    def stopWriting(self):\n",
    "        \"\"\"Stop Writing exited frames to a video file.\"\"\"\n",
    "        self._videoFilename= None\n",
    "        self._videoEncoding= None\n",
    "        self._videoWrite = None\n",
    "    \n",
    "    def _writeVideoFrame(self):\n",
    "        if not self.isWritingVideo:\n",
    "            return\n",
    "        \n",
    "        if self._videoWriter is None:\n",
    "            fps = self._capture.get(cv2.CAP_PROP_FPS)\n",
    "            if fps == 0.0:\n",
    "                # The capture's FPS is unknown so use an estimate.\n",
    "                if self._framesElapsed < 20:\n",
    "                    #Wait until more frames elapse so that the estimate\n",
    "                    # is more stable\n",
    "                    return\n",
    "                else:\n",
    "                    fps = self._fpsEstimate\n",
    "            size = (int(self._capture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                    int(self._capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "                    \n",
    "            self._videoWriter = cv2.VideoWriter(self._videoFilename,\n",
    "                                                self._videoEncoding,\n",
    "                                                fps, size)\n",
    "        self._videoWriter.write(self.frame)\n",
    "\n",
    "\n",
    "                                        \n",
    "\n",
    "class WindowManager(object):\n",
    "    def __init__(self, windowName, keypressCallback = None):\n",
    "        self.keypressCallback = keypressCallback\n",
    "        self._windowName = windowName\n",
    "        self._isWindowCreated = False\n",
    "        \n",
    "    @property\n",
    "    def isWindowCreated(self):\n",
    "        return self._isWindowCreated\n",
    "\n",
    "    def createWindow(self):\n",
    "        cv2.namedWindow(self._windowName)\n",
    "        self._isWindowCreated = True\n",
    "\n",
    "    def show(self,frame):\n",
    "        cv2.imshow(self._windowName, frame)\n",
    "\n",
    "    def destroyWindow(self):\n",
    "        cv2.destroyWindow(self._windowName)\n",
    "        self._isWindowCreated = False\n",
    "    \n",
    "    def processEvents(self):\n",
    "        keycode = cv2.waitKey(1)\n",
    "        if self.keypressCallback is not None and keycode != -1:\n",
    "        # Discard any non-ASCII info encoded by GTK\n",
    "            keycode &= 0xFF\n",
    "            self.keypressCallback(keycode)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf40a8b-b76a-413b-8058-72dc375891b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cameo py\n",
    "import cv2\n",
    "import filters\n",
    "from managers import WindowManager, CaptureManager\n",
    "\n",
    "class Cameo(object):\n",
    "    def __init__(self):\n",
    "        self._windowManager = WindowManager ('Cameo',self.onKeypress)\n",
    "        self._captureManager = CaptureManager(\n",
    "            cv2.VideoCapture(0),self._windowManager, True)\n",
    "   \n",
    "        \n",
    "    def run(self):\n",
    "        self._windowManager.createWindow()\n",
    "        while self._windowManager.isWindowCreated:\n",
    "            self._captureManager.enterFrame()\n",
    "            frame = self._captureManager.frame\n",
    "\n",
    "            # TODO: filter frame\n",
    "            filters.strokeEdges(frame,frame)\n",
    "            \n",
    "\n",
    "\n",
    " \n",
    "            self._captureManager.exitFrame()\n",
    "            self._windowManager.processEvents()\n",
    "\n",
    "    def onKeypress(self, keycode):\n",
    "        \"\"\" Handle a keypress.\n",
    "        space -> Take a screenshot\n",
    "        tab -> Start/stop recording a screencast.\n",
    "        escape -> Quit.\n",
    "        \"\"\"\n",
    "        if keycode == 32: #space\n",
    "            self._captureManager.writeImage('screenshot.png')\n",
    "\n",
    "        elif keycode == 9: #tab\n",
    "            if not self._captureManager.isWritingVideo:\n",
    "                self._captureManager.startWritingVideo(\n",
    "                    'screencast.avi'\n",
    "                )\n",
    "            else:\n",
    "                self._captureManager.stopWritingVideo()\n",
    "        elif keycode == 27: #escape\n",
    "            self._windowManager.destroyWindow()\n",
    "\n",
    "if __name__==\"main\":\n",
    "    Cameo().run\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184cb7d-e3ce-44e7-859e-501516880728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main driver\n",
    "import cv2\n",
    "from cameo import Cameo\n",
    "\n",
    "main = Cameo()\n",
    "\n",
    "main.run()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd20667-9ac2-422e-8932-7e83c6b66c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters py\n",
    "import cv2\n",
    "import numpy\n",
    "import utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def recolorRC(src, dst):\n",
    "    \"\"\"Simulate conversion from BGR to RC (red, cyan).\n",
    "    \n",
    "    The source and destination images must both be in BGR format.\n",
    "    \n",
    "    Blues and greens are replaced with cyans. The effect is similar\n",
    "    to Technicolor Process 2 (used in early color movies) and CGA\n",
    "    Palette 3 (used in early color PCs).\n",
    "    \n",
    "    Pseudocode:\n",
    "    dst.b = dst.g = 0.5 * (src.b + src.g)\n",
    "    dst.r = src.r\n",
    "    \n",
    "    \"\"\"\n",
    "    b, g, r = cv2.split(src)\n",
    "    cv2.addWeighted(b, 0.5, g, 0.5, 0, b)\n",
    "    cv2.merge((b, b, r), dst)\n",
    "\n",
    "\n",
    "def recolorRGV(src, dst):\n",
    "    \"\"\"Simulate conversion from BGR to RGV (red, green, value).\n",
    "    \n",
    "    The source and destination images must both be in BGR format.\n",
    "    \n",
    "    Blues are desaturated. The effect is similar to Technicolor\n",
    "    Process 1 (used in early color movies).\n",
    "    \n",
    "    Pseudocode:\n",
    "    dst.b = min(src.b, src.g, src.r)\n",
    "    dst.g = src.g\n",
    "    dst.r = src.r\n",
    "    \n",
    "    \"\"\"\n",
    "    b, g, r = cv2.split(src)\n",
    "    cv2.min(b, g, b)\n",
    "    cv2.min(b, r, b)\n",
    "    cv2.merge((b, g, r), dst)\n",
    "\n",
    "\n",
    "def recolorCMV(src, dst):\n",
    "    \"\"\"Simulate conversion from BGR to CMV (cyan, magenta, value).\n",
    "    \n",
    "    The source and destination images must both be in BGR format.\n",
    "    \n",
    "    Yellows are desaturated. The effect is similar to CGA Palette 1\n",
    "    (used in early color PCs).\n",
    "    \n",
    "    Pseudocode:\n",
    "    dst.b = max(src.b, src.g, src.r)\n",
    "    dst.g = src.g\n",
    "    dst.r = src.r\n",
    "    \n",
    "    \"\"\"\n",
    "    b, g, r = cv2.split(src)\n",
    "    cv2.max(b, g, b)\n",
    "    cv2.max(b, r, b)\n",
    "    cv2.merge((b, g, r), dst)\n",
    "\n",
    "\n",
    "def blend(foregroundSrc, backgroundSrc, dst, alphaMask):\n",
    "    \n",
    "    # Calculate the normalized alpha mask.\n",
    "    maxAlpha = numpy.iinfo(alphaMask.dtype).max\n",
    "    normalizedAlphaMask = (1.0 / maxAlpha) * alphaMask\n",
    "    \n",
    "    # Calculate the normalized inverse alpha mask.\n",
    "    normalizedInverseAlphaMask = \\\n",
    "        numpy.ones_like(normalizedAlphaMask)\n",
    "    normalizedInverseAlphaMask[:] = \\\n",
    "        normalizedInverseAlphaMask - normalizedAlphaMask\n",
    "    \n",
    "    # Split the channels from the sources.\n",
    "    foregroundChannels = cv2.split(foregroundSrc)\n",
    "    backgroundChannels = cv2.split(backgroundSrc)\n",
    "    \n",
    "    # Blend each channel.\n",
    "    numChannels = len(foregroundChannels)\n",
    "    i = 0\n",
    "    while i < numChannels:\n",
    "        backgroundChannels[i][:] = \\\n",
    "            normalizedAlphaMask * foregroundChannels[i] + \\\n",
    "            normalizedInverseAlphaMask * backgroundChannels[i]\n",
    "        i += 1\n",
    "    \n",
    "    # Merge the blended channels into the destination.\n",
    "    cv2.merge(backgroundChannels, dst)\n",
    "\n",
    "\n",
    "def strokeEdges(src, dst, blurKsize = 7, edgeKsize = 5):\n",
    "    if blurKsize >= 3:\n",
    "        blurredSrc = cv2.medianBlur(src, blurKsize)\n",
    "        graySrc = cv2.cvtColor(blurredSrc, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        graySrc = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.Laplacian(graySrc, cv2.CV_8U, graySrc, ksize = edgeKsize)\n",
    "    normalizedInverseAlpha = (1.0 / 255) * (255 - graySrc)\n",
    "    channels = cv2.split(src)\n",
    "    for channel in channels:\n",
    "        channel[:] = channel * normalizedInverseAlpha\n",
    "    cv2.merge(channels, dst)\n",
    "\n",
    "\n",
    "class VFuncFilter(object):\n",
    "    \"\"\"A filter that applies a function to V (or all of BGR).\"\"\"\n",
    "    \n",
    "    def __init__(self, vFunc = None, dtype = numpy.uint8):\n",
    "        length = numpy.iinfo(dtype).max + 1\n",
    "        self._vLookupArray = utils.createLookupArray(vFunc, length)\n",
    "    \n",
    "    def apply(self, src, dst):\n",
    "        \"\"\"Apply the filter with a BGR or gray source/destination.\"\"\"\n",
    "        srcFlatView = utils.flatView(src)\n",
    "        dstFlatView = utils.flatView(dst)\n",
    "        utils.applyLookupArray(self._vLookupArray, srcFlatView,\n",
    "                               dstFlatView)\n",
    "\n",
    "class VCurveFilter(VFuncFilter):\n",
    "    \"\"\"A filter that applies a curve to V (or all of BGR).\"\"\"\n",
    "    \n",
    "    def __init__(self, vPoints, dtype = numpy.uint8):\n",
    "        VFuncFilter.__init__(self, utils.createCurveFunc(vPoints),\n",
    "                             dtype)\n",
    "\n",
    "\n",
    "class BGRFuncFilter(object):\n",
    "    \"\"\"A filter that applies different functions to each of BGR.\"\"\"\n",
    "    \n",
    "    def __init__(self, vFunc = None, bFunc = None, gFunc = None,\n",
    "                 rFunc = None, dtype = numpy.uint8):\n",
    "        length = numpy.iinfo(dtype).max + 1\n",
    "        self._bLookupArray = utils.createLookupArray(\n",
    "            utils.createCompositeFunc(bFunc, vFunc), length)\n",
    "        self._gLookupArray = utils.createLookupArray(\n",
    "            utils.createCompositeFunc(gFunc, vFunc), length)\n",
    "        self._rLookupArray = utils.createLookupArray(\n",
    "            utils.createCompositeFunc(rFunc, vFunc), length)\n",
    "    \n",
    "    def apply(self, src, dst):\n",
    "        \"\"\"Apply the filter with a BGR source/destination.\"\"\"\n",
    "        b, g, r = cv2.split(src)\n",
    "        utils.applyLookupArray(self._bLookupArray, b, b)\n",
    "        utils.applyLookupArray(self._gLookupArray, g, g)\n",
    "        utils.applyLookupArray(self._rLookupArray, r, r)\n",
    "        cv2.merge([b, g, r], dst)\n",
    "\n",
    "class BGRCurveFilter(BGRFuncFilter):\n",
    "    \"\"\"A filter that applies different curves to each of BGR.\"\"\"\n",
    "    \n",
    "    def __init__(self, vPoints = None, bPoints = None,\n",
    "                 gPoints = None, rPoints = None, dtype = numpy.uint8):\n",
    "        BGRFuncFilter.__init__(self,\n",
    "                               utils.createCurveFunc(vPoints),\n",
    "                               utils.createCurveFunc(bPoints),\n",
    "                               utils.createCurveFunc(gPoints),\n",
    "                               utils.createCurveFunc(rPoints), dtype)\n",
    "\n",
    "class BGRCrossProcessCurveFilter(BGRCurveFilter):\n",
    "    \"\"\"A filter that applies cross-process-like curves to BGR.\"\"\"\n",
    "    \n",
    "    def __init__(self, dtype = numpy.uint8):\n",
    "        BGRCurveFilter.__init__(\n",
    "            self,\n",
    "            bPoints = [(0,20),(255,235)],\n",
    "            gPoints = [(0,0),(56,39),(208,226),(255,255)],\n",
    "            rPoints = [(0,0),(56,22),(211,255),(255,255)],\n",
    "            dtype = dtype)\n",
    "\n",
    "class BGRPortraCurveFilter(BGRCurveFilter):\n",
    "    \"\"\"A filter that applies Portra-like curves to BGR.\"\"\"\n",
    "    \n",
    "    def __init__(self, dtype = numpy.uint8):\n",
    "        BGRCurveFilter.__init__(\n",
    "            self,\n",
    "            vPoints = [(0,0),(23,20),(157,173),(255,255)],\n",
    "            bPoints = [(0,0),(41,46),(231,228),(255,255)],\n",
    "            gPoints = [(0,0),(52,47),(189,196),(255,255)],\n",
    "            rPoints = [(0,0),(69,69),(213,218),(255,255)],\n",
    "            dtype = dtype)\n",
    "\n",
    "class BGRProviaCurveFilter(BGRCurveFilter):\n",
    "    \"\"\"A filter that applies Provia-like curves to BGR.\"\"\"\n",
    "    \n",
    "    def __init__(self, dtype = numpy.uint8):\n",
    "        BGRCurveFilter.__init__(\n",
    "            self,\n",
    "            bPoints = [(0,0),(35,25),(205,227),(255,255)],\n",
    "            gPoints = [(0,0),(27,21),(196,207),(255,255)],\n",
    "            rPoints = [(0,0),(59,54),(202,210),(255,255)],\n",
    "            dtype = dtype)\n",
    "\n",
    "class BGRVelviaCurveFilter(BGRCurveFilter):\n",
    "    \"\"\"A filter that applies Velvia-like curves to BGR.\"\"\"\n",
    "    \n",
    "    def __init__(self, dtype = numpy.uint8):\n",
    "        BGRCurveFilter.__init__(\n",
    "            self,\n",
    "            vPoints = [(0,0),(128,118),(221,215),(255,255)],\n",
    "            bPoints = [(0,0),(25,21),(122,153),(165,206),(255,255)],\n",
    "            gPoints = [(0,0),(25,21),(95,102),(181,208),(255,255)],\n",
    "            rPoints = [(0,0),(41,28),(183,209),(255,255)],\n",
    "            dtype = dtype)\n",
    "\n",
    "\n",
    "class VConvolutionFilter(object):\n",
    "    \"\"\"A filter that applies a convolution to V (or all of BGR).\"\"\"\n",
    "    \n",
    "    def __init__(self, kernel):\n",
    "        self._kernel = kernel\n",
    "    \n",
    "    def apply(self, src, dst):\n",
    "        \"\"\"Apply the filter with a BGR or gray source/destination.\"\"\"\n",
    "        cv2.filter2D(src, -1, self._kernel, dst)\n",
    "\n",
    "class BlurFilter(VConvolutionFilter):\n",
    "    \"\"\"A blur filter with a 2-pixel radius.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        kernel = numpy.array([[0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                              [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                              [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                              [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                              [0.04, 0.04, 0.04, 0.04, 0.04]])\n",
    "        VConvolutionFilter.__init__(self, kernel)\n",
    "\n",
    "class SharpenFilter(VConvolutionFilter):\n",
    "    \"\"\"A sharpen filter with a 1-pixel radius.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        kernel = numpy.array([[-1, -1, -1],\n",
    "                              [-1,  9, -1],\n",
    "                              [-1, -1, -1]])\n",
    "        VConvolutionFilter.__init__(self, kernel)\n",
    "\n",
    "class FindEdgesFilter(VConvolutionFilter):\n",
    "    \"\"\"An edge-finding filter with a 1-pixel radius.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        kernel = numpy.array([[-1, -1, -1],\n",
    "                              [-1,  8, -1],\n",
    "                              [-1, -1, -1]])\n",
    "        VConvolutionFilter.__init__(self, kernel)\n",
    "\n",
    "class EmbossFilter(VConvolutionFilter):\n",
    "    \"\"\"An emboss filter with a 1-pixel radius.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        kernel = numpy.array([[-2, -1, 0],\n",
    "                              [-1,  1, 1],\n",
    "                              [ 0,  1, 2]])\n",
    "        VConvolutionFilter.__init__(self, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b64c28-7454-43e6-ba2c-32ae1c5d6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils py\n",
    "import cv2\n",
    "import numpy\n",
    "import scipy.interpolate\n",
    "\n",
    "def createFlatView(array):\n",
    "    \"\"\"Return a 1D view of an array of any dimensionality.\"\"\"\n",
    "    flatView = array.view()\n",
    "    flatView.shape = array.size\n",
    "    return flatView\n",
    "\n",
    "def createLookupArray(func, length = 256):\n",
    "    \"\"\"Return a lookup for whole-number inputs to a function.\n",
    "    \n",
    "    The lookup values are clamped to [0, length - 1].\n",
    "    \n",
    "    \"\"\"\n",
    "    if func is None:\n",
    "        return None\n",
    "    lookupArray = numpy.empty(length)\n",
    "    i = 0\n",
    "    while i < length:\n",
    "        func_i = func(i)\n",
    "        lookupArray[i] = min(max(0, func_i), length - 1)\n",
    "        i += 1\n",
    "    return lookupArray\n",
    "\n",
    "def applyLookupArray(lookupArray, src, dst):\n",
    "    \"\"\"Map a source to a destination using a lookup.\"\"\"\n",
    "    if lookupArray is None:\n",
    "        return\n",
    "    dst[:] = lookupArray[src]\n",
    "\n",
    "def createCurveFunc(points):\n",
    "    \"\"\"Return a function derived from control points.\"\"\"\n",
    "    if points is None:\n",
    "        return None\n",
    "    numPoints = len(points)\n",
    "    if numPoints < 2:\n",
    "        return None\n",
    "    xs, ys = zip(*points)\n",
    "    if numPoints < 4:\n",
    "        kind = 'linear'\n",
    "        # 'quadratic' is not implemented.\n",
    "    else:\n",
    "        kind = 'cubic'\n",
    "    return scipy.interpolate.interp1d(xs, ys, kind,\n",
    "                                      bounds_error = False)\n",
    "\n",
    "def createCompositeFunc(func0, func1):\n",
    "    \"\"\"Return a composite of two functions.\"\"\"\n",
    "    if func0 is None:\n",
    "        return func1\n",
    "    if func1 is None:\n",
    "        return func0\n",
    "    return lambda x: func0(func1(x))\n",
    "\n",
    "def isGray(image):\n",
    "    \"\"\"Return True if the image has one channel per pixel.\"\"\"\n",
    "    return image.ndim < 3\n",
    "\n",
    "def widthHeightDividedBy(image, divisor):\n",
    "    \"\"\"Return an image's dimensions, divided by a value.\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    return (w/divisor, h/divisor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
